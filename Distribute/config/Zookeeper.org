* 注册中心/配置中心(服务发现)
** 定义
配置中心是个基于“发布-订阅”模型的通讯组件，客户端（Pub和Sub）各自跟配置中心建立长连接，并告知配置中心自己要发布/订阅什么数据。
配置中心的用户分为两个关键色：发布者 和 订阅者。它们彼此看不到对方的存在，维系它们的是其共同关注的数据，通过“数据标识（DataId和GroupId）”联系在一起。
• 「服务发现」中的「服务」：可以等同于ip+port；一个服务在运行时，需要活性检查（或者叫健康检查），也就是服务是有状态的（至少包括可用和不可用两种状态）
• 「配置管理」中的「配置」：key=value；配置一经生成，一直存在，不需要活性检查，也就是说配置是没有状态的
** 应用场景
RPC服务地址订阅（软负载）、消息中心地址订阅、配置数据实时订阅（DRM）
** 设计要求
1. 从数据上看，分为持久化配置和非持久化配置
2. 从性能上看，分为读多写少和读少写多，对于订阅者对推送到达率和时效要求很高
3. 从可用性上看，要求在服务不可用的情况下也能工作，必要时能通过单机操作；通过心跳机制来做故障转移
4. 从运维角度看，需要有后台监控和管理，对于持久化配置需要能够查看历史和回滚
** 衡量指标
** 设计原则
1. CAP中，优先满足AP，C通过最终一致性保证
2. 可以牺牲数据一致性去满足高可用
** 选型
Eureka
Zookeeper
CS
DM
Etcd
Maglev

* 选型
** Eureka
Eureka 是 Netflix 出品的用于实现服务注册和发现的工具，Spring Cloud 封装了 Netflix 公司开发的 Eureka 模块来实现服务注册和发现
*** 概念
Applecation-server:服务提供者
Application-cliene:服务消费者
*** 自我保护机制
核心用于区分客户端正常下线和服务端网络故障
*** 数据一致性
通过P2P机制保障，数据冲突通过lastDirtyTimestamp基于服务维度的版本号保障

** CS
*** 概念
简单来说，就是注册中心，提供数据的发布/订阅功能，可以对标zookeeper。
但是不同的是，ZK面向的是读多写少的场景。ZK集群中，
follower和observer节点都只负责读请求，而把写请求委托给master节点。
CS面对的场景，会有频繁的写请求。因此，它不能和ZK一样，设计成单节点处理写请求。
它有多个节点可以处理写请求。每次写请求处理完成，就会采用多写的方式，同步给其他机器。
如下图，这是CS2.0的架构图。这种情况下，会有一个问题，由于集群中的节点是两两互写的方式，
那么当集群扩容后，两两互写的压力会非常大，以至于达到网络瓶颈。
针对这个问题，在3.0版本里，整个架构进行了彻底地转型。

* 演进
** 集群版本
主从结构，注册结果存储在内存和磁盘
**** 解决问题
1.问题：流量瓶颈
   解决：CS将地址动态推送到客户端，客户端直接请求服务提供方
2.问题：单点故障
   解决：客户端本地会缓存收到的地址，即使CS挂掉也可以调用服务.
3.问题：对于长连接场景负载不均
   解决：每个请求都可以通过随机或轮询的方式选择服务器，做到请求级别的负载均衡
**** 存在的问题
1.数据一致性问题：数据都存在本地磁盘中，没有同步机制
2.性能降低。通过客户端方式同步，单机需要保存原生客户端的数据，还需要保存集群客户端的数据，需要占用两份内存，并且会导致推送效率的下降

*** Redis版本
**** 解决问题
1.问题：持久化数据的一致性问题
   解决：Mysql集群有完备的机制保证数据一致性
2.问题：持久化数据的容灾性
   解决：Mysql主从、DM Server集群无中心化、DM Server缓存、客户端快照、客户端容灾目录
**** 存在的问题
问题：非持久化数据性能和容灾问题

*** 1.0版本
**** 解决问题
1.问题：非持久化数据容灾
   解决：CS集群去中心化
2.问题：非持久化数据一致性
    解决：CS两两互写
**** 存在的问题
  随着业务规模的扩大，两两互写的机制会导致性能降低

*** 2.0版本
架构设计：
Session集群负责与客户端的交互，可动态扩容
DataServer集群解决数据的容灾，数量固定

实现原理：
客户端将地址注册到session，session异步复写到DataServer
CS以1s为周期压缩后推送到所有session上
session缓存dataServer推送的数据，只保存本地数据和推送的压缩数据
好处：session集群可根据业务规模水平扩容，而DataServer集群数量固定不会影响集群性能
   2.单一职责，方便运维

*** 如何保证数据一致性（最终一致性）：
1.问题：client写session的时候，session挂了，怎么办
解决：client选择其他session重新写入
2.问题：session写入DataServer失败了怎么办
解决：对于每一个写任务，session通过重试确保最终写成功
3.问题：DataServer挂了怎么办
解决：机器恢复后，在有写入操作时，session会自动将本地全量数据写入到DataServer中.
4.问题：session复写DataServer的时候数据冲突了，怎么办？
解决：固定顺序复写，不会冲突？
5.问题：DataServer在推送数据给session的时候失败了，怎么办
解决：重试
6.问题：session挂了，怎么办？
解决：client和session有心跳机制，会连接其他session并获取最新的数据

*** 特性
1、唯一标识：应用通过唯一的DataId+Group发布一份数据，其他应用可以通过DataId+Group订阅该配置，后续DataId+Group发生变化，其他应用可以实时感知。CS会根据DataId、Group自动合并DatumId数据。因为DatumId是唯一的，所以CS可以实现集群多点写多点读，而ZooKeeper作为强一致性的代表，他只能单点写多点读。
2、集中与非集中的权衡：CS在client与server相互发现之前是集中式的，统一管理并且提供地址路由；client与server相互连接之后，CS则会退隐后台，当地址变动时则会再次提供地址路由，这个阶段CS对于client与server的相互请求连接而言是透明的。
3、负载均衡：因为所有地址信息都是经由CS，所以在这里做负载均衡也是理所应当的，通过调整地址的权重来实现负载均衡是比较轻松的。当然也可以在client与CS连接处做一层负载均衡。
4、弱一致性：作为分布式系统，CS同样也遵循CAP定理，在CAP三个属性中，根据阿里实际的应用场景，做了取舍。最后是基于BASE模型，在保证高可用性（保证集群的推送能力及延时）、容错性（集群中部分机器出现异常，不能影响整个集群的服务能力）的情况下，牺牲了一致性。在发布者随机选择一台server发布数据时，如果这时候有订阅者立刻连接到另外一台server上订阅数据时，数据可能还未及时同步过来，为了满足推送延时，必须给订阅者一个及时的响应，这时推送出去的数据，就不是最新的，不过，等数据同步过来后，CS会重新通知一次订阅者，通过这种补偿机制，实现了数据最终一致。
5、容灾策略：CS的设计上充分考虑了灾难场景：CS的机器宕机、CS集群全部不可用、机房断网等。
  当一台CS服务器不可用时，客户端感知到连接断开后，会进行自动重连，直到寻找到一台可用的服务器为止。
  如果是一台CS不可用的场景，恢复的过程很快，1-3秒内客户端会全部重新找到可用机器。
  当CS集群全部不可用时，如果zookeeper遇到的话，客户端就完全不可用了。
  ConfigClient在设计的时候考虑到这样的场景，加入了客户端缓存的策略：将最新的数据写入本地磁盘，如果遇到服务器不可用的情况，从本地读取数据先初始化。
  当机房断网的时候，客户端和服务端的连接可能都不会收到连接断开的事件，CS内部加入了心跳机制，从业务层保证网络是可用的。
  如果客户端或者服务端两个心跳周期内没有收到数据，那么认为这个连接已经不可用了，会进入重连步骤。另外客户端在选择CS服务器的时候，
  会根据自己位置就进选择机房内部的CS，这样在机房断网的情况下，绝大多数的客户端是不需要重连的，CS集群之间的连接断开后，
  会重新聚合数据，将机房内部可用的数据推送给客户端。


* ZooKeeper
ZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务，是Google的Chubby一个开源的实现，是Hadoop和Hbase的重要组件。
它是一个为分布式应用提供一致性服务的软件，提供的功能包括：配置维护、名字服务、分布式同步、组服务等。

* Nacos
分布式静态配置中心，提供配置实时推送服务。
** 原理
*** 多级缓存
*** 服务端数据同步方案
1.数据变更
数据写入时会先执行insert插入，如果insert产生了主键冲突异常，那么会执行更新操作。
数据库的操作使用的jdbcTemplate。数据持久化包括两部分，写入配置数据，即config_info表，还有写入历史数据，即his_config_info表。这也是我们在控制台看到的历史数据轨迹。
2.配置数据变更事件
服务端配置了对ConfigDataChangeEvent的Listener，AsyncNotifyService，我们来看下这个事件的处理逻辑。
3.通知所有服务器
首先会获取所有服务器的机器地址，这个和客户端的逻辑相同，使用地址服务组件，通过SERVER_ADDRESSS_URL去获取服务器地址列表，同时通过定时器去检查服务器地址的有效性。
针对服务端地址列表中的每一个地址，也就是每一台服务器，都产生一个NotifySingleTask，对应的每个NotifySingleTask产生一个AsyncTask，交由httpClient去执行。
4.执行更新任务
服务端处理更新任务的controller为NotifyController，对应的方法为notifyConfigInfo，这里要做的操作是更改本地文件的配置信息。首先会产生一个DumpTask,并交由TaskManager进行处理。对应的DumpTask有一个任务处理器DumpProcess。dump任务处理器会先找到变更的数据，ConfigInfo，如果找到了，那么就将最新变更的数据写入本地文件，然后更新md5信息。类似于客户端的CachgData，客户端维持了一个CacheItem，这个cache里面只保存了key(group+dataId),和对应的md5。并且会触发一个LocalDataChangeEnvent。
5.本地数据变更
LocalDataChangeEnvent由LongPullingService进行处理，同样的产生一个DataChangeTask任务，这个任务的处理是从所有的客户端连接中，找到当前任务的订阅该任务的连接，并将key返回给客户端。具体的见后文服务端处理客户端轮询逻辑。
*** 长轮询方案
1.客户端长轮询
客户端发起轮询，http请求的超时时间设置为30S，客户端收到返回结果后进行下一次轮询。
2.客户端请求数据
根据客户端提交的dataId,groupId,可以找到服务端缓存的CacheItem，里面有服务端配置信息的MD5，对比客户端提交的MD5，如果两者不相同，说明该配置发生了变化，将其加入变化的列表里面。如果客户端订阅的配置信息有变更（changedGroup列表不为空），那么将变化的dataId,groupId按照约定的格式返回客户端。
3.服务端异步Servlet
如果请求到来时没有配置发生变化，服务端并不会立刻返回客户端，而是由异步的Servlet线程去处理。
关于异步Servlet的相关知识，Servlet容器分配的线程会释放，但是请求不会立刻返回，具体请Google。从这里我们能看到长轮询的具体逻辑是在ClientLongPulling线程中，我们来详细看下。
4.服务端ClientLongPulling
在ClientLongPulling的run方法里面，首先会将当前的轮询加入的一个订阅列表allSubs,里面保存了所以未返回的长轮询订阅关系。然后起了一个ScheduledFuture<?> java.util.concurrent.ScheduledExecutorService.schedule(Runnable command, long delay, TimeUnit unit)线程，也就是在超时时间到了后，比较客户端与服务端的MD5是否相同，向客户端返回发送变化的dataId,groupId.当线程开始执行时会首先将当前轮询订阅关系删除。也就是异步的Servlet会在超时时间到了才向客户端返回数据，那如果在超时等待中间数据发送了变化，该如何处理呢？
5.轮询期间数据发生变更
前面说过服务端数据发送变更后最终会触发LocalDataChangeEnvent事件，而这个时间就是由LongPullingService进行处理的。监听到LocalDataChangeEnvent事件后，会产生一个DataChangeTask，任务的执行也很简单，遍历所有的订阅关系allSubs，查找客户端请求包含当前变化的dataId，groupId的客户端，找到了就从订阅关系列表中删除当前订阅，并向客户端返回dataId,groupId。注意到这里是对单个事件进行处理的，如果在一个轮询期间有多个数据发送了变更，那么在这次轮询中只会返回一个dataId，groupId。客户端收到请求后会立刻进行下一次轮询，才会把其余的变更数据一次返回给客户端。
6.长轮询逻辑
+ 请求到达时有数据变更，则返回所有变更数据；
+ 请求到达时没有数据变更，客户端设置了不立刻返回，那么使用异步Servlet进行处理。如果这期间数据没有发生变化，超时时间（考虑网络传输，比客户端设置的超时时间提前500ms）到达后，向客户端返回数据；
+ 如果在这期间有数据发生变化，立刻向客户端返回变更的数据。
7.零拷贝

** 问题
Nacos通过http 1.0长轮询的方式已经运行了10年，在当时来看在web服务领域实现是比较简单高效的，
但是在如今200W长连接规模下http连接不断断开重建造成的系统性能问题愈发严重，在8C16G的机器规格下最多支撑1W的连接，
并且集群的规模在300个左右也到了上线。后续将着手于整体通信协议的改造，基于长连接的方式来实现Client-Server和Server-Server间的通信，
可以有效提升单机支持的业务规模，提高SLA。

** 其他应用
*** 基于DM+AOP实现接口限流
核心原理：通过注解检测某个接口的class+method是否在配置中，如果在配置中则拦截
*** 基于DM+TD实现数据库主备切换



** VS

VS : 一种集群路由软件负载均衡系统
VS: A Cluster Routing And Soft Load Balance Service

** 构想（Concept）
在ISO OIS模型网络层里的两台主机要想互相通信，首先需要知道对方的IP的地址。
在一个分布式的系统环境中，一个服务可能就会多台主机来提供，我们称之为集群（Cluster）。
一个服务请求转发送到哪一台以及如何发送就成了一个现实问题。
在早期，人们是通过一种叫作网络负载器来实现的（如F5），但F5毕竟是硬件，配置、管理及维护都相当不便，而且价格不菲。
后来淘宝开发了LVS（Linux Virtual Server），虽然它可以代替F5，但仍然是充当一个网关（Gateway）的角色，
因此所有的请求都会经过它，随着流量的增加，它就会成为一个瓶颈，何况LVS开发的主要目前不是为内部集群服务的，而是外部接入网关。

   A  |  B
      |
      |
在LB/LVS模型下通信的双方机器是互不可见的，仅通过暴露的VIP进行通信

** 原理（How it works）
VS构想之初就被定义为“一种集群路由软件负载均衡系统”，所以我们想做的就是一种使用普通PC机的为各个集群间提供路由负载服务的系统。
在种构系统下，目的机的地址首先被注册到VS上，之后主机先向VS查询路由信息，然后便根据此路由信息向目的地址发起直连，
完全不需要第三方的参与，不存在通信瓶颈，达到网络利用的最大化。
而这VS这边对结点的状态进行维护，客户端也要定期更新Server端信息，确保路正确，如下图所示：

VS原理图

** 设计、挑战与实现（Design, Challenge and Implement）
因此根据我们的设想，它必须满足：
1.它必须能对路由信息负责，所有结点的配置变更都需要自动且及实的响应
（比如某台机器挂了，那么我们就不能路由到那里去了；某个集群机器上线了，我们就要在自己的路由表里增加此结点）
2.它必须能让应用友好接入，实现最少代码修改成本，且支持自定义配置；
3.它必须方便部署，无特殊配置需要；
4.它必须方便管理、维护，有统一配置入口；
5.它必须有非常好的容灾特性，不能因我们故障导致连接不通或请求阻塞。

第3点：比较好实现，我们将VS分为了Server与Client两端，Server端使用普通web应用，其在淘宝非常成熟，而且有很多自动化工具，部署起来需要的仅仅是一个war包而已。
挑战1：如何自动响应配置变更，减少人力干涉
第1、4点：我们设计了一个web 操作界面，实现对配置信息的集中管理，只需要点几下，就可以轻松对结点信息进行增删改查。但有些PE仍然觉得很麻烦，因为他们可能会管理几十个集群，每个集群又有几十台机器。为了解决这个问题，这样成千上百的IP用手工来进行输入的确是非常麻烦。为此我们引入了armory里nodegroup的概念，在armory系统中，每个app都有自己的group名称，只要提供group名称，就可以查询到机器列表信息，这样一来，PE在注册自己的应用的时候，只需要提供一个nodegroup，我们就可会定期地去更新该app的主机列表，机器列表抓取、机器上线不再需要PE的介入了。

挑战2：如何准确快速响应机器结点故障，最大力度减少路由失败
那么机器下线、故障又怎么办呢？这点看似与前面的问题相同，其实不然，对于机器上线，我们要实时性的要求不是那么高，10分钟、30分钟甚至几小生效都没有问题。
但机器故障、下线就不行了。为了解决这个问题我们设计Server对每个机器结点进行健康检测，我们为每个接入的app设计了一个健康检测任务，每个健康检测任务由一个单程scheduler完全异步执行HTTP或TCP健康检测，间隔3秒。
但这样并不完美，实际我们发现有时候网络不稳定，很可能造因为网络延迟而造成判断不准确。为了解决这个问题当第一次失败的时候，我们会启动一个fast check任务，间隔500ms，如果两次fast check仍然失败，我们才认为其正的失败。
当从失败状态转变成成功状态时也是三次检测才成功，但没有fast check。我们这样做的想法是快速下线，但慢慢上线，因此上线慢不问题不太，至少不会路由失败，但如果测试成功也采用fast check，就会造成过多的fast check任务，
如果网络继续不稳定的话，就可能导致fast check堆积，大大影响Server端的性能。根据实际压测结果，我们的服务器单机能支持2w个IP的健康检查，性能非常高。

健康检测有限状态机

挑战3：如何保证客户端高性能、高可靠性
第2、5点：这其实是一个很矛盾的问题，因为我们又不想像F5那样充当网络网关，干涉机器间的网络传输，又希望对用户的网络请求进行路由控制。
最开始我们想的是编写一个VS的客户端，但这个客户必须有很高的性能，不能因为我们慢而已阻塞其请求，因此我们精心设计了路由信息更新，
每当一个线程发现数据过期时，我们只会放行该线程去执行更新任务，其它线程仍然使用老数据，这个的难点在于，对某个应用的路由信息访问会存在非常大的大并发量。
在Java上我们可以使用concurrent hash map对解决，但C/C++里我们又怎么办呢？
这里我们参考了IBM的一篇论文（http://www.almaden.ibm.com/laborday/people/m/michael/spaa-2002.pdf），
完全自己实现了C语言上的lock-free hash table（参见：http://www.atatech.org/article/detail/7966/0），经实际测试，
根据C客户端的压测报告，TPS高达1700W。同时，为了客户端更新请求泛洪，我们在服务器返回数据时指向客户端需要缓存的时间，
也就是说客户端在自己缓存过期前，不会向服务端请求更新数据，这样就大大减少了server的负担。
但这样随着客户端的增加，服务器的负担仍然会越来越大。后期，我们为了进一步减少服务器的负担，使用了HTTP长轮询的方式，
在这种方式下，每个客户端与服务器只会维持一个TCP长连接。正常性能下，服务器不会立即返回，客户端就会一直挂着，
直到某个应用的路由信息发生变化或超时，服务才会返回。为了保证变更不丢失，客户端在请求的时候还需要附带上上次数据版本号。


除了性能之外，我们的客户最关心的就是稳定性问题。我们首先列举了VS可能出现的故障点：
1.VS集群中一台服务器故障；
2.VS集群所有服务器均故障；
3.VS配置出错，配置清空；
4.Client故障，无法服务。

第1、2点：VS 集群不可用的问题，如上所述我们为客户端增加了本地缓存。在HTTP长轮询模式中，我们会单独起一个线程与做，它与主服务线程毫无关系，所以这个更新过程更是完全异步的，这样就完全不会阻塞用户进程了。

第3、4点：为了对客户端本地的缓存进行保护，每次客户端缓存更新时，我们还会将其写入磁盘缓存。这样万一如果Client故障而且Server也连不通的情况下，我们也可以通过重启来进行快速恢复服务，保证网络调用正常。我们精心设计Client端是不接受空数据的，也就是说如果某个时候即便Server配置被删除或者配置错误，Client端的数据也不会被覆盖，从而保证最基本的调用通畅。对于DNS-F客户端如果万一Client挂掉，我们也可以通过快速重启来解决。

t_14279_1381985930_1496454697.png

VS数据更新流程

挑战4：面对众多语言、架构，如何做到统一接入
VS服务的对象是整个集团，因此会遇到各种各样的客户端，如PHP、Java、C/C++、JavaScript等等。因为考虑到客户端其实还是挺简单的，刚开始我们还可以针对某种语言编写对应的客户端，但随着功能的添加，各种客户端的维护就成为了非常头疼的问题。另一方面，在实现推广中我们发现，有些应用如TANX是使用多进程来进行网络访问的，原有的内存模型显然无法实现多进程间的缓存共享，如果为一个进程单独开一个client的话，这样显然又是相当浪费的。为了解决这个问题，我们提出了DNS Filter的概念，也就是我们会在客户端本地单独启一个进程，这个进程占用53号端口。客户在使用的时候，首先更改resolv.conf，将首先DNS指向127.0.0.1，即本机。这样我们的进程就能过滤DNS解析请求了，实现对上层客户端的透明支撑,如果不是我们管辖的域名，我们就直接转发出去。通过TANX应用的实际使用，这种方案切实可行。根据测试提供的压测报告，本客户端在当前单线程的时候TPS能支持至1.8w，我们认为这对大多数情况都是够用的了。

而在于服务端，我们使用了最通用的HTTP+JSON做为信息传输的载体，完全不依赖客户端上层应用。同时我们基于此还开放了SDK，同样基于HTTP，对于可以非常对自己的域名进行自动化维护。

VS V.S CS
首先从服务内容上：CS充当的一个配置中心的角色，它与DM一样，只是承担的是状态敏感的配置信息，其核心在于状态敏感配置的同步。而VS的服务内容是负载，其核心是保证有效路由与路由控制。比如说使用VS我可以让某个应用不能调用，或者降低调用的比重。所以在我看来，他们两个并没有太多的重复，用户使用VS不一定使用CS，使用CS也不一定使用VS。

其次从数据角度上：CS使用的是TCP主动推送方式，数据是非持久的；VS采用的则是TCP+UDP推拉结合的方式，数据持久在DM上。在数据有效性验证上，CS采用与连接绑定的方式，一旦连接断开就意味着数据失效且从内存移除，而VS采用的则是主动检测的方式，目前支持HTTP与TCP两种方式，如果检测失败，则认为数据失效但不从磁盘上删除。

最后从将来的发展来看：CS会继续着重在配置信息推送上，重点服务HSF；而VS则会向路由访问控制方向发展，支持等自定义路由控制，要做到只需在VS进行一些简单配置，就可以实现对应用相互调用的控制。

现状（Today’s VS）
VS刚诞生不久，线上已接入10个应用，路由结点50台+，客户机器100台+，其中包括TANX这种日调用量超40亿的大客户）都已开始使用VS来实现集群间直连调用。更为关键的是很多大型应用，如阿里旺旺、阿里云计算都对VS产生了强烈的兴趣，特别是阿里云，其中有一个应用ESC， 1w+的机器正准备接入。

未来（Future’s VS）
我们将接管现有的LVS方案，实现集群间完全透明的端到端访问，大大减少运营成本，还将提供访问控制与流量，让用户轻松控制客户端的调用访问，实现功能全面的集群路由及软件负载均衡服务。

